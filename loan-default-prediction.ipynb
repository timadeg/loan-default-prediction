{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# # Imports\n",
    "\n",
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# No warnings about setting value on copy of slice\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Display up to 60 columns of a dataframe\n",
    "pd.set_option('display.max_columns', 60)\n",
    "\n",
    "# Matplotlib visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default font size\n",
    "plt.rcParams['font.size'] = 24\n",
    "\n",
    "# Internal ipython tool for setting figure size\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "# Seaborn for visualization\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 2)\n",
    "\n",
    "# Splitting data into training and testing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\epam\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: DtypeWarning: Columns (135,204,274,417) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "      <th>f31</th>\n",
       "      <th>...</th>\n",
       "      <th>f750</th>\n",
       "      <th>f751</th>\n",
       "      <th>f752</th>\n",
       "      <th>f753</th>\n",
       "      <th>f754</th>\n",
       "      <th>f755</th>\n",
       "      <th>f756</th>\n",
       "      <th>f757</th>\n",
       "      <th>f758</th>\n",
       "      <th>f759</th>\n",
       "      <th>f760</th>\n",
       "      <th>f761</th>\n",
       "      <th>f762</th>\n",
       "      <th>f763</th>\n",
       "      <th>f764</th>\n",
       "      <th>f765</th>\n",
       "      <th>f766</th>\n",
       "      <th>f767</th>\n",
       "      <th>f768</th>\n",
       "      <th>f769</th>\n",
       "      <th>f770</th>\n",
       "      <th>f771</th>\n",
       "      <th>f772</th>\n",
       "      <th>f773</th>\n",
       "      <th>f774</th>\n",
       "      <th>f775</th>\n",
       "      <th>f776</th>\n",
       "      <th>f777</th>\n",
       "      <th>f778</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.686842</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>13699</td>\n",
       "      <td>7201.0</td>\n",
       "      <td>4949.0</td>\n",
       "      <td>126.75</td>\n",
       "      <td>126.03</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7607</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>612922</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.5171</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>0.8476</td>\n",
       "      <td>0.7876</td>\n",
       "      <td>1.097851e+09</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>998046.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.00</td>\n",
       "      <td>89.00</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3451</td>\n",
       "      <td>0.030594</td>\n",
       "      <td>1.7418</td>\n",
       "      <td>1.5271</td>\n",
       "      <td>0.8474</td>\n",
       "      <td>0.4715</td>\n",
       "      <td>0.028362</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>2.5162</td>\n",
       "      <td>2.0037</td>\n",
       "      <td>0.019636</td>\n",
       "      <td>4.4352</td>\n",
       "      <td>4.2676</td>\n",
       "      <td>-0.1524</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.6280</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>5</td>\n",
       "      <td>2.14</td>\n",
       "      <td>-1.54</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.7873</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>10</td>\n",
       "      <td>0.782776</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>84645</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>123.52</td>\n",
       "      <td>121.35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>0.6555</td>\n",
       "      <td>245815</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>0.3909</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>0.6903</td>\n",
       "      <td>8.449459e+08</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>754416.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5666</td>\n",
       "      <td>0.120442</td>\n",
       "      <td>1.1963</td>\n",
       "      <td>1.0322</td>\n",
       "      <td>0.4843</td>\n",
       "      <td>0.2389</td>\n",
       "      <td>0.130160</td>\n",
       "      <td>2.7659</td>\n",
       "      <td>1.9523</td>\n",
       "      <td>1.4059</td>\n",
       "      <td>0.115277</td>\n",
       "      <td>3.2763</td>\n",
       "      <td>2.7962</td>\n",
       "      <td>-0.3097</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.203</td>\n",
       "      <td>-0.2300</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>6</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>-0.6787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500080</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>83607</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>127.76</td>\n",
       "      <td>126.49</td>\n",
       "      <td>7</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>1385872</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.5508</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>1.308478e+09</td>\n",
       "      <td>89</td>\n",
       "      <td>54</td>\n",
       "      <td>1037651.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.43</td>\n",
       "      <td>94.37</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5627</td>\n",
       "      <td>0.226336</td>\n",
       "      <td>3.3277</td>\n",
       "      <td>3.4166</td>\n",
       "      <td>1.8321</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.103307</td>\n",
       "      <td>6.8623</td>\n",
       "      <td>5.2963</td>\n",
       "      <td>4.1282</td>\n",
       "      <td>0.219729</td>\n",
       "      <td>8.1381</td>\n",
       "      <td>7.3269</td>\n",
       "      <td>-0.1909</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-0.540</td>\n",
       "      <td>-0.572</td>\n",
       "      <td>-0.3985</td>\n",
       "      <td>-5.18</td>\n",
       "      <td>13</td>\n",
       "      <td>2.89</td>\n",
       "      <td>-1.73</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>10</td>\n",
       "      <td>0.439874</td>\n",
       "      <td>1100</td>\n",
       "      <td>3</td>\n",
       "      <td>82642</td>\n",
       "      <td>7542.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>132.94</td>\n",
       "      <td>133.58</td>\n",
       "      <td>7</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>704687</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>0.5923</td>\n",
       "      <td>0.7881</td>\n",
       "      <td>0.8230</td>\n",
       "      <td>0.8158</td>\n",
       "      <td>1.472752e+09</td>\n",
       "      <td>93</td>\n",
       "      <td>55</td>\n",
       "      <td>1115721.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>114.63</td>\n",
       "      <td>102.92</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6899</td>\n",
       "      <td>0.054630</td>\n",
       "      <td>1.3748</td>\n",
       "      <td>1.3421</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.4810</td>\n",
       "      <td>0.081205</td>\n",
       "      <td>2.5571</td>\n",
       "      <td>2.0593</td>\n",
       "      <td>1.6653</td>\n",
       "      <td>0.056470</td>\n",
       "      <td>3.2516</td>\n",
       "      <td>3.0631</td>\n",
       "      <td>-0.1770</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.635</td>\n",
       "      <td>-0.745</td>\n",
       "      <td>-0.5100</td>\n",
       "      <td>-2.04</td>\n",
       "      <td>4</td>\n",
       "      <td>1.29</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.2498</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>9</td>\n",
       "      <td>0.502749</td>\n",
       "      <td>2900</td>\n",
       "      <td>4</td>\n",
       "      <td>79124</td>\n",
       "      <td>89.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>122.72</td>\n",
       "      <td>112.77</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>51985</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.5263</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>1.442916e+09</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>536400.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.9179</td>\n",
       "      <td>0.085330</td>\n",
       "      <td>7.2175</td>\n",
       "      <td>6.2262</td>\n",
       "      <td>3.1446</td>\n",
       "      <td>1.6149</td>\n",
       "      <td>0.074286</td>\n",
       "      <td>15.9080</td>\n",
       "      <td>12.5688</td>\n",
       "      <td>9.9844</td>\n",
       "      <td>0.067540</td>\n",
       "      <td>17.5561</td>\n",
       "      <td>15.6079</td>\n",
       "      <td>-0.4444</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>-0.182</td>\n",
       "      <td>-0.4277</td>\n",
       "      <td>-11.12</td>\n",
       "      <td>26</td>\n",
       "      <td>6.11</td>\n",
       "      <td>-3.82</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>-0.5399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   f1  f2        f3    f4  f5     f6      f7      f8      f9     f10  \\\n",
       "0   1  126  10  0.686842  1100   3  13699  7201.0  4949.0  126.75  126.03   \n",
       "1   2  121  10  0.782776  1100   3  84645   240.0  1625.0  123.52  121.35   \n",
       "2   3  126  10  0.500080  1100   3  83607  1800.0  1527.0  127.76  126.49   \n",
       "3   4  134  10  0.439874  1100   3  82642  7542.0  1730.0  132.94  133.58   \n",
       "4   5  109   9  0.502749  2900   4  79124    89.0   491.0  122.72  112.77   \n",
       "\n",
       "   f13     f14     f15      f16     f17     f18     f19     f20     f21  \\\n",
       "0    7  0.7607  0.7542   612922  0.7236  0.7236  0.5171  0.7236  0.8476   \n",
       "1    7  0.6555  0.6555   245815  0.6341  0.6341  0.3909  0.6667  0.6903   \n",
       "2    7  0.7542  0.7542  1385872  0.7542  0.7542  0.5508  0.7542  0.8091   \n",
       "3    7  0.8017  0.7881   704687  0.7881  0.7881  0.5923  0.7881  0.8230   \n",
       "4    6  0.5263  0.5263    51985  0.5263  0.5263  0.3044  0.5405  0.5556   \n",
       "\n",
       "      f22           f23  f24  f25        f26   f27   f28     f29     f30  \\\n",
       "0  0.7876  1.097851e+09   89   66   998046.0  89.0  89.0   89.00   89.00   \n",
       "1  0.6903  8.449459e+08   78   50   754416.0  78.0  78.0   78.00   78.00   \n",
       "2  0.7807  1.308478e+09   89   54  1037651.0  89.0  89.0  100.43   94.37   \n",
       "3  0.8158  1.472752e+09   93   55  1115721.0  93.0  93.0  114.63  102.92   \n",
       "4  0.5455  1.442916e+09   60   21   536400.0  60.0  60.0   60.00   60.00   \n",
       "\n",
       "    f31  ...     f750      f751    f752    f753    f754    f755      f756  \\\n",
       "0  89.0  ...   2.3451  0.030594  1.7418  1.5271  0.8474  0.4715  0.028362   \n",
       "1  78.0  ...   1.5666  0.120442  1.1963  1.0322  0.4843  0.2389  0.130160   \n",
       "2  89.0  ...   4.5627  0.226336  3.3277  3.4166  1.8321  0.9979  0.103307   \n",
       "3  93.0  ...   1.6899  0.054630  1.3748  1.3421  0.7982  0.4810  0.081205   \n",
       "4  60.0  ...  11.9179  0.085330  7.2175  6.2262  3.1446  1.6149  0.074286   \n",
       "\n",
       "      f757     f758    f759      f760     f761     f762    f763  f764  f765  \\\n",
       "0   3.1611   2.5162  2.0037  0.019636   4.4352   4.2676 -0.1524     1 -0.40   \n",
       "1   2.7659   1.9523  1.4059  0.115277   3.2763   2.7962 -0.3097     1 -0.17   \n",
       "2   6.8623   5.2963  4.1282  0.219729   8.1381   7.3269 -0.1909     1 -0.58   \n",
       "3   2.5571   2.0593  1.6653  0.056470   3.2516   3.0631 -0.1770     1 -0.75   \n",
       "4  15.9080  12.5688  9.9844  0.067540  17.5561  15.6079 -0.4444     1 -0.18   \n",
       "\n",
       "    f766   f767    f768   f769  f770  f771  f772  f773    f774    f775  f776  \\\n",
       "0 -0.560 -0.440 -0.6280  -3.14     5  2.14 -1.54  1.18  0.1833  0.7873     1   \n",
       "1 -0.275 -0.203 -0.2300  -1.38     6  0.54 -0.24  0.13  0.1926 -0.6787     1   \n",
       "2 -0.540 -0.572 -0.3985  -5.18    13  2.89 -1.73  1.04  0.2521  0.7258     1   \n",
       "3 -0.635 -0.745 -0.5100  -2.04     4  1.29 -0.89  0.66  0.2498  0.7119     1   \n",
       "4 -0.280 -0.182 -0.4277 -11.12    26  6.11 -3.82  2.51  0.2282 -0.5399     0   \n",
       "\n",
       "   f777  f778  loss  \n",
       "0     0     5     0  \n",
       "1     0     5     0  \n",
       "2     0     5     0  \n",
       "3     0     5     0  \n",
       "4     0     5     0  \n",
       "\n",
       "[5 rows x 771 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # # Data Cleaning and Formatting\n",
    "\n",
    "# # Load in the Data and Examine\n",
    "\n",
    "# Read in data into a dataframe \n",
    "data = pd.read_csv('./loan-default-prediction/train_v2.csv')\n",
    "\n",
    "# Display top of dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "59f931574dd75b9b1b750403420b04c3216cef56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105471, 771)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "0afdcffbcd53eb30140dc2c8bcd922f9b7cef9d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105471 entries, 0 to 105470\n",
      "Columns: 771 entries, id to loss\n",
      "dtypes: float64(653), int64(99), object(19)\n",
      "memory usage: 620.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# # Data Types and Missing Values\n",
    "\n",
    "# See the column data types and non-missing values\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "e66dd9afd8d014c48077843b26f304a9c8e8c130"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f137</th>\n",
       "      <th>f138</th>\n",
       "      <th>f206</th>\n",
       "      <th>f207</th>\n",
       "      <th>f276</th>\n",
       "      <th>f277</th>\n",
       "      <th>f338</th>\n",
       "      <th>f390</th>\n",
       "      <th>f391</th>\n",
       "      <th>f419</th>\n",
       "      <th>f420</th>\n",
       "      <th>f469</th>\n",
       "      <th>f472</th>\n",
       "      <th>f534</th>\n",
       "      <th>f537</th>\n",
       "      <th>f626</th>\n",
       "      <th>f627</th>\n",
       "      <th>f695</th>\n",
       "      <th>f698</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8090000000000000</td>\n",
       "      <td>754485076006959972352</td>\n",
       "      <td>3200000000000</td>\n",
       "      <td>38600000000000000</td>\n",
       "      <td>7900000000000000</td>\n",
       "      <td>683091368180479950848</td>\n",
       "      <td>7610000000000</td>\n",
       "      <td>10370164393071999997033054208</td>\n",
       "      <td>13621142007705000132589703585884798976</td>\n",
       "      <td>137000000000</td>\n",
       "      <td>511000000000000</td>\n",
       "      <td>569877634360569973702656</td>\n",
       "      <td>3427303293502300223465356001280</td>\n",
       "      <td>240811094251680005357568</td>\n",
       "      <td>1185103615651699994464937312256</td>\n",
       "      <td>11724173453590999285553430528</td>\n",
       "      <td>16027029142402000396838501389877379072</td>\n",
       "      <td>8700000000000000000</td>\n",
       "      <td>8010000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2250000000000</td>\n",
       "      <td>15300000000000000</td>\n",
       "      <td>392000000000</td>\n",
       "      <td>1690000000000000</td>\n",
       "      <td>92300000000000</td>\n",
       "      <td>2140000000000000000</td>\n",
       "      <td>796594176</td>\n",
       "      <td>5098137566366599989877014528</td>\n",
       "      <td>5366154527659000357778647583412977664</td>\n",
       "      <td>9483264</td>\n",
       "      <td>1593188352</td>\n",
       "      <td>107000000000000000</td>\n",
       "      <td>9894337169928600158208</td>\n",
       "      <td>251470350285930004480</td>\n",
       "      <td>161196782629860003268263936</td>\n",
       "      <td>6391495663130699779035627520</td>\n",
       "      <td>7158933769610900052770065343332745216</td>\n",
       "      <td>5890000000000000000</td>\n",
       "      <td>5030000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186000000000000</td>\n",
       "      <td>6910365323840000000</td>\n",
       "      <td>23700000000000</td>\n",
       "      <td>389000000000000000</td>\n",
       "      <td>10300000000000</td>\n",
       "      <td>69200000000000000</td>\n",
       "      <td>461000000000</td>\n",
       "      <td>26400269714792999161039945728</td>\n",
       "      <td>36117033568522998807722429270944907264</td>\n",
       "      <td>36051866452</td>\n",
       "      <td>63500000000000</td>\n",
       "      <td>313319151143610023936</td>\n",
       "      <td>222812827058929985669562368</td>\n",
       "      <td>116067852739909992448</td>\n",
       "      <td>61668865475731997253959680</td>\n",
       "      <td>36420952401170000260810932224</td>\n",
       "      <td>56027915541865997900093655676589441024</td>\n",
       "      <td>24512111987574001664</td>\n",
       "      <td>19855991371293999104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44500000000000000</td>\n",
       "      <td>11225194901267999096832</td>\n",
       "      <td>16098514954</td>\n",
       "      <td>35000000000000</td>\n",
       "      <td>22200000000000</td>\n",
       "      <td>295000000000000000</td>\n",
       "      <td>1330000000000</td>\n",
       "      <td>9333818143939599917454983168</td>\n",
       "      <td>12638526060843999893906772076814925824</td>\n",
       "      <td>5621900678</td>\n",
       "      <td>9380000000000</td>\n",
       "      <td>2641626213765599994052608</td>\n",
       "      <td>24452856014536001129152839155712</td>\n",
       "      <td>202899352692079984640</td>\n",
       "      <td>126293716597939998795235328</td>\n",
       "      <td>15267506423634001098621059072</td>\n",
       "      <td>24362045267421999852972382580757233664</td>\n",
       "      <td>9660000000000000000</td>\n",
       "      <td>6960000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52152926246</td>\n",
       "      <td>108000000000000</td>\n",
       "      <td>442000000000</td>\n",
       "      <td>1870000000000000</td>\n",
       "      <td>3630000000000</td>\n",
       "      <td>23100000000000000</td>\n",
       "      <td>2240000000000</td>\n",
       "      <td>196004669899870011305513451520</td>\n",
       "      <td>428213273484070002013091334592080642048</td>\n",
       "      <td>279000000000</td>\n",
       "      <td>659000000000000</td>\n",
       "      <td>68300000000000</td>\n",
       "      <td>922000000000000000</td>\n",
       "      <td>654000000000000000</td>\n",
       "      <td>89341826582645997305856</td>\n",
       "      <td>238204359524660008028924280832</td>\n",
       "      <td>550170020491249969340152709153269219328</td>\n",
       "      <td>108505460071560003584</td>\n",
       "      <td>94766610066210996224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                f137                     f138            f206  \\\n",
       "0   8090000000000000    754485076006959972352   3200000000000   \n",
       "1      2250000000000        15300000000000000    392000000000   \n",
       "2    186000000000000      6910365323840000000  23700000000000   \n",
       "3  44500000000000000  11225194901267999096832     16098514954   \n",
       "4        52152926246          108000000000000    442000000000   \n",
       "\n",
       "                 f207              f276                   f277           f338  \\\n",
       "0   38600000000000000  7900000000000000  683091368180479950848  7610000000000   \n",
       "1    1690000000000000    92300000000000    2140000000000000000      796594176   \n",
       "2  389000000000000000    10300000000000      69200000000000000   461000000000   \n",
       "3      35000000000000    22200000000000     295000000000000000  1330000000000   \n",
       "4    1870000000000000     3630000000000      23100000000000000  2240000000000   \n",
       "\n",
       "                             f390                                     f391  \\\n",
       "0   10370164393071999997033054208   13621142007705000132589703585884798976   \n",
       "1    5098137566366599989877014528    5366154527659000357778647583412977664   \n",
       "2   26400269714792999161039945728   36117033568522998807722429270944907264   \n",
       "3    9333818143939599917454983168   12638526060843999893906772076814925824   \n",
       "4  196004669899870011305513451520  428213273484070002013091334592080642048   \n",
       "\n",
       "           f419             f420                       f469  \\\n",
       "0  137000000000  511000000000000   569877634360569973702656   \n",
       "1       9483264       1593188352         107000000000000000   \n",
       "2   36051866452   63500000000000      313319151143610023936   \n",
       "3    5621900678    9380000000000  2641626213765599994052608   \n",
       "4  279000000000  659000000000000             68300000000000   \n",
       "\n",
       "                               f472                      f534  \\\n",
       "0   3427303293502300223465356001280  240811094251680005357568   \n",
       "1            9894337169928600158208     251470350285930004480   \n",
       "2       222812827058929985669562368     116067852739909992448   \n",
       "3  24452856014536001129152839155712     202899352692079984640   \n",
       "4                922000000000000000        654000000000000000   \n",
       "\n",
       "                              f537                            f626  \\\n",
       "0  1185103615651699994464937312256   11724173453590999285553430528   \n",
       "1      161196782629860003268263936    6391495663130699779035627520   \n",
       "2       61668865475731997253959680   36420952401170000260810932224   \n",
       "3      126293716597939998795235328   15267506423634001098621059072   \n",
       "4          89341826582645997305856  238204359524660008028924280832   \n",
       "\n",
       "                                      f627                   f695  \\\n",
       "0   16027029142402000396838501389877379072    8700000000000000000   \n",
       "1    7158933769610900052770065343332745216    5890000000000000000   \n",
       "2   56027915541865997900093655676589441024   24512111987574001664   \n",
       "3   24362045267421999852972382580757233664    9660000000000000000   \n",
       "4  550170020491249969340152709153269219328  108505460071560003584   \n",
       "\n",
       "                   f698  \n",
       "0   8010000000000000000  \n",
       "1   5030000000000000000  \n",
       "2  19855991371293999104  \n",
       "3   6960000000000000000  \n",
       "4  94766610066210996224  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.select_dtypes(include=['object']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "5e62f799ae387d53f80a3261f6ec2ead90cef0a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>f13</th>\n",
       "      <th>f14</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "      <th>f31</th>\n",
       "      <th>...</th>\n",
       "      <th>f750</th>\n",
       "      <th>f751</th>\n",
       "      <th>f752</th>\n",
       "      <th>f753</th>\n",
       "      <th>f754</th>\n",
       "      <th>f755</th>\n",
       "      <th>f756</th>\n",
       "      <th>f757</th>\n",
       "      <th>f758</th>\n",
       "      <th>f759</th>\n",
       "      <th>f760</th>\n",
       "      <th>f761</th>\n",
       "      <th>f762</th>\n",
       "      <th>f763</th>\n",
       "      <th>f764</th>\n",
       "      <th>f765</th>\n",
       "      <th>f766</th>\n",
       "      <th>f767</th>\n",
       "      <th>f768</th>\n",
       "      <th>f769</th>\n",
       "      <th>f770</th>\n",
       "      <th>f771</th>\n",
       "      <th>f772</th>\n",
       "      <th>f773</th>\n",
       "      <th>f774</th>\n",
       "      <th>f775</th>\n",
       "      <th>f776</th>\n",
       "      <th>f777</th>\n",
       "      <th>f778</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105289.000000</td>\n",
       "      <td>105370.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105371.000000</td>\n",
       "      <td>105423.000000</td>\n",
       "      <td>1.054710e+05</td>\n",
       "      <td>105312.000000</td>\n",
       "      <td>105448.000000</td>\n",
       "      <td>105448.000000</td>\n",
       "      <td>105011.000000</td>\n",
       "      <td>103631.000000</td>\n",
       "      <td>103773.000000</td>\n",
       "      <td>1.047730e+05</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>1.047730e+05</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>104773.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>104618.000000</td>\n",
       "      <td>104013.000000</td>\n",
       "      <td>105469.000000</td>\n",
       "      <td>105469.000000</td>\n",
       "      <td>105469.000000</td>\n",
       "      <td>105469.000000</td>\n",
       "      <td>105238.000000</td>\n",
       "      <td>104671.000000</td>\n",
       "      <td>104671.000000</td>\n",
       "      <td>104671.000000</td>\n",
       "      <td>104137.000000</td>\n",
       "      <td>105313.000000</td>\n",
       "      <td>105313.000000</td>\n",
       "      <td>103631.000000</td>\n",
       "      <td>105471.0</td>\n",
       "      <td>105470.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>104407.000000</td>\n",
       "      <td>103946.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "      <td>105471.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52736.000000</td>\n",
       "      <td>134.603171</td>\n",
       "      <td>8.246883</td>\n",
       "      <td>0.499066</td>\n",
       "      <td>2678.488874</td>\n",
       "      <td>7.354533</td>\n",
       "      <td>47993.704317</td>\n",
       "      <td>2974.336018</td>\n",
       "      <td>2436.363718</td>\n",
       "      <td>134.555225</td>\n",
       "      <td>134.596862</td>\n",
       "      <td>11.349015</td>\n",
       "      <td>0.696120</td>\n",
       "      <td>0.678140</td>\n",
       "      <td>4.010386e+06</td>\n",
       "      <td>0.673572</td>\n",
       "      <td>0.649476</td>\n",
       "      <td>0.510736</td>\n",
       "      <td>0.685829</td>\n",
       "      <td>0.746194</td>\n",
       "      <td>0.726551</td>\n",
       "      <td>3.014404e+09</td>\n",
       "      <td>82.179803</td>\n",
       "      <td>63.420561</td>\n",
       "      <td>1.108926e+06</td>\n",
       "      <td>92.134281</td>\n",
       "      <td>86.490683</td>\n",
       "      <td>103.850939</td>\n",
       "      <td>91.672933</td>\n",
       "      <td>90.045642</td>\n",
       "      <td>...</td>\n",
       "      <td>8.115740</td>\n",
       "      <td>0.138719</td>\n",
       "      <td>6.130018</td>\n",
       "      <td>5.500419</td>\n",
       "      <td>3.390325</td>\n",
       "      <td>2.158617</td>\n",
       "      <td>0.119762</td>\n",
       "      <td>10.602136</td>\n",
       "      <td>8.782883</td>\n",
       "      <td>7.341984</td>\n",
       "      <td>0.136195</td>\n",
       "      <td>12.921228</td>\n",
       "      <td>12.103488</td>\n",
       "      <td>-0.253806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.471021</td>\n",
       "      <td>-0.476605</td>\n",
       "      <td>-0.471572</td>\n",
       "      <td>-0.491973</td>\n",
       "      <td>-8.786110</td>\n",
       "      <td>17.422543</td>\n",
       "      <td>5.800976</td>\n",
       "      <td>-4.246788</td>\n",
       "      <td>3.273059</td>\n",
       "      <td>0.233852</td>\n",
       "      <td>0.014797</td>\n",
       "      <td>0.310246</td>\n",
       "      <td>0.322847</td>\n",
       "      <td>175.951589</td>\n",
       "      <td>0.799585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30446.999458</td>\n",
       "      <td>14.725467</td>\n",
       "      <td>1.691535</td>\n",
       "      <td>0.288752</td>\n",
       "      <td>1401.010943</td>\n",
       "      <td>5.151112</td>\n",
       "      <td>35677.136048</td>\n",
       "      <td>2546.551085</td>\n",
       "      <td>2262.950221</td>\n",
       "      <td>13.824682</td>\n",
       "      <td>14.504043</td>\n",
       "      <td>3.669019</td>\n",
       "      <td>0.242829</td>\n",
       "      <td>0.241969</td>\n",
       "      <td>6.623236e+06</td>\n",
       "      <td>0.232733</td>\n",
       "      <td>0.246958</td>\n",
       "      <td>0.173126</td>\n",
       "      <td>0.241082</td>\n",
       "      <td>0.237795</td>\n",
       "      <td>0.233876</td>\n",
       "      <td>2.070153e+09</td>\n",
       "      <td>28.316093</td>\n",
       "      <td>32.431329</td>\n",
       "      <td>3.015962e+05</td>\n",
       "      <td>36.904526</td>\n",
       "      <td>30.830152</td>\n",
       "      <td>40.968777</td>\n",
       "      <td>32.681102</td>\n",
       "      <td>12.535453</td>\n",
       "      <td>...</td>\n",
       "      <td>10.319706</td>\n",
       "      <td>0.115468</td>\n",
       "      <td>8.121672</td>\n",
       "      <td>7.143152</td>\n",
       "      <td>4.685670</td>\n",
       "      <td>3.163447</td>\n",
       "      <td>0.063974</td>\n",
       "      <td>12.899936</td>\n",
       "      <td>10.998444</td>\n",
       "      <td>9.435965</td>\n",
       "      <td>0.112682</td>\n",
       "      <td>14.973088</td>\n",
       "      <td>14.151640</td>\n",
       "      <td>0.237795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.284702</td>\n",
       "      <td>0.194983</td>\n",
       "      <td>0.263993</td>\n",
       "      <td>0.141869</td>\n",
       "      <td>9.684043</td>\n",
       "      <td>18.548936</td>\n",
       "      <td>6.508555</td>\n",
       "      <td>4.828265</td>\n",
       "      <td>3.766746</td>\n",
       "      <td>0.073578</td>\n",
       "      <td>1.039439</td>\n",
       "      <td>0.462597</td>\n",
       "      <td>0.467567</td>\n",
       "      <td>298.294043</td>\n",
       "      <td>4.321120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>106.820000</td>\n",
       "      <td>103.140000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.623600e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.230000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.970000</td>\n",
       "      <td>-0.950000</td>\n",
       "      <td>-0.963000</td>\n",
       "      <td>-0.945000</td>\n",
       "      <td>-85.450000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-43.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-18.439600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26368.500000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.248950</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11255.000000</td>\n",
       "      <td>629.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>124.290000</td>\n",
       "      <td>123.870000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.661500</td>\n",
       "      <td>4.117930e+05</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.635600</td>\n",
       "      <td>0.432500</td>\n",
       "      <td>0.669400</td>\n",
       "      <td>0.729700</td>\n",
       "      <td>0.710500</td>\n",
       "      <td>1.508475e+09</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>9.267570e+05</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700900</td>\n",
       "      <td>0.058420</td>\n",
       "      <td>1.202000</td>\n",
       "      <td>1.122200</td>\n",
       "      <td>0.595700</td>\n",
       "      <td>0.323300</td>\n",
       "      <td>0.076388</td>\n",
       "      <td>2.535400</td>\n",
       "      <td>1.957400</td>\n",
       "      <td>1.530850</td>\n",
       "      <td>0.056469</td>\n",
       "      <td>3.361800</td>\n",
       "      <td>3.055100</td>\n",
       "      <td>-0.270300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.710000</td>\n",
       "      <td>-0.630000</td>\n",
       "      <td>-0.699000</td>\n",
       "      <td>-0.575900</td>\n",
       "      <td>-11.530000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>-5.700000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>-0.704275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52736.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.498267</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>76530.000000</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>1786.000000</td>\n",
       "      <td>128.460000</td>\n",
       "      <td>129.080000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.770500</td>\n",
       "      <td>0.754200</td>\n",
       "      <td>1.672764e+06</td>\n",
       "      <td>0.745800</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.539200</td>\n",
       "      <td>0.761900</td>\n",
       "      <td>0.818200</td>\n",
       "      <td>0.798200</td>\n",
       "      <td>2.233947e+09</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.115136e+06</td>\n",
       "      <td>94.780000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.261950</td>\n",
       "      <td>0.083637</td>\n",
       "      <td>3.081600</td>\n",
       "      <td>2.840700</td>\n",
       "      <td>1.627000</td>\n",
       "      <td>0.957600</td>\n",
       "      <td>0.103507</td>\n",
       "      <td>5.855800</td>\n",
       "      <td>4.711500</td>\n",
       "      <td>3.830000</td>\n",
       "      <td>0.082008</td>\n",
       "      <td>7.564900</td>\n",
       "      <td>7.045500</td>\n",
       "      <td>-0.181800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.480000</td>\n",
       "      <td>-0.480000</td>\n",
       "      <td>-0.503100</td>\n",
       "      <td>-5.440000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>0.251800</td>\n",
       "      <td>0.375400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79103.500000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.749494</td>\n",
       "      <td>3700.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>80135.000000</td>\n",
       "      <td>4679.000000</td>\n",
       "      <td>3411.000000</td>\n",
       "      <td>149.080000</td>\n",
       "      <td>148.310000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.831900</td>\n",
       "      <td>0.815100</td>\n",
       "      <td>4.731222e+06</td>\n",
       "      <td>0.804900</td>\n",
       "      <td>0.796700</td>\n",
       "      <td>0.627000</td>\n",
       "      <td>0.823000</td>\n",
       "      <td>0.876100</td>\n",
       "      <td>0.855900</td>\n",
       "      <td>4.031443e+09</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>1.293732e+06</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>128.750000</td>\n",
       "      <td>109.890000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.210900</td>\n",
       "      <td>0.217172</td>\n",
       "      <td>7.569000</td>\n",
       "      <td>6.859100</td>\n",
       "      <td>4.152300</td>\n",
       "      <td>2.595800</td>\n",
       "      <td>0.156382</td>\n",
       "      <td>13.316650</td>\n",
       "      <td>10.987400</td>\n",
       "      <td>9.148000</td>\n",
       "      <td>0.219453</td>\n",
       "      <td>16.463500</td>\n",
       "      <td>15.448100</td>\n",
       "      <td>-0.123900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.230000</td>\n",
       "      <td>-0.330000</td>\n",
       "      <td>-0.248000</td>\n",
       "      <td>-0.420000</td>\n",
       "      <td>-2.390000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>-1.010000</td>\n",
       "      <td>4.440000</td>\n",
       "      <td>0.283600</td>\n",
       "      <td>0.737100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>105471.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>7900.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>88565.000000</td>\n",
       "      <td>9968.000000</td>\n",
       "      <td>11541.000000</td>\n",
       "      <td>172.950000</td>\n",
       "      <td>175.270000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.037873e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.563049e+10</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>2.603664e+06</td>\n",
       "      <td>218.730000</td>\n",
       "      <td>160.490000</td>\n",
       "      <td>220.630000</td>\n",
       "      <td>159.900000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>91.821900</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>77.673100</td>\n",
       "      <td>68.652100</td>\n",
       "      <td>48.579400</td>\n",
       "      <td>36.473500</td>\n",
       "      <td>0.497640</td>\n",
       "      <td>112.770300</td>\n",
       "      <td>95.343600</td>\n",
       "      <td>82.293100</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>127.346800</td>\n",
       "      <td>120.425000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>58.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.040000</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>11.092000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 752 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id             f1             f2             f3  \\\n",
       "count  105471.000000  105471.000000  105471.000000  105471.000000   \n",
       "mean    52736.000000     134.603171       8.246883       0.499066   \n",
       "std     30446.999458      14.725467       1.691535       0.288752   \n",
       "min         1.000000     103.000000       1.000000       0.000006   \n",
       "25%     26368.500000     124.000000       8.000000       0.248950   \n",
       "50%     52736.000000     129.000000       9.000000       0.498267   \n",
       "75%     79103.500000     148.000000       9.000000       0.749494   \n",
       "max    105471.000000     176.000000      11.000000       0.999994   \n",
       "\n",
       "                  f4             f5             f6             f7  \\\n",
       "count  105471.000000  105471.000000  105471.000000  105289.000000   \n",
       "mean     2678.488874       7.354533   47993.704317    2974.336018   \n",
       "std      1401.010943       5.151112   35677.136048    2546.551085   \n",
       "min      1100.000000       1.000000       0.000000       1.000000   \n",
       "25%      1500.000000       4.000000   11255.000000     629.000000   \n",
       "50%      2200.000000       4.000000   76530.000000    2292.000000   \n",
       "75%      3700.000000      10.000000   80135.000000    4679.000000   \n",
       "max      7900.000000      17.000000   88565.000000    9968.000000   \n",
       "\n",
       "                  f8             f9            f10            f13  \\\n",
       "count  105370.000000  105471.000000  105471.000000  105471.000000   \n",
       "mean     2436.363718     134.555225     134.596862      11.349015   \n",
       "std      2262.950221      13.824682      14.504043       3.669019   \n",
       "min         1.000000     106.820000     103.140000       2.000000   \n",
       "25%       746.000000     124.290000     123.870000       9.000000   \n",
       "50%      1786.000000     128.460000     129.080000      11.000000   \n",
       "75%      3411.000000     149.080000     148.310000      13.000000   \n",
       "max     11541.000000     172.950000     175.270000      40.000000   \n",
       "\n",
       "                 f14            f15           f16            f17  \\\n",
       "count  105371.000000  105423.000000  1.054710e+05  105312.000000   \n",
       "mean        0.696120       0.678140  4.010386e+06       0.673572   \n",
       "std         0.242829       0.241969  6.623236e+06       0.232733   \n",
       "min         0.000000       0.000000  0.000000e+00       0.000000   \n",
       "25%         0.680000       0.661500  4.117930e+05       0.656000   \n",
       "50%         0.770500       0.754200  1.672764e+06       0.745800   \n",
       "75%         0.831900       0.815100  4.731222e+06       0.804900   \n",
       "max         1.000000       1.000000  7.037873e+07       1.000000   \n",
       "\n",
       "                 f18            f19            f20            f21  \\\n",
       "count  105448.000000  105448.000000  105011.000000  103631.000000   \n",
       "mean        0.649476       0.510736       0.685829       0.746194   \n",
       "std         0.246958       0.173126       0.241082       0.237795   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.635600       0.432500       0.669400       0.729700   \n",
       "50%         0.736000       0.539200       0.761900       0.818200   \n",
       "75%         0.796700       0.627000       0.823000       0.876100   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                 f22           f23            f24            f25  \\\n",
       "count  103773.000000  1.047730e+05  105471.000000  105471.000000   \n",
       "mean        0.726551  3.014404e+09      82.179803      63.420561   \n",
       "std         0.233876  2.070153e+09      28.316093      32.431329   \n",
       "min         0.000000  1.623600e+05       0.000000       0.000000   \n",
       "25%         0.710500  1.508475e+09      81.000000      45.000000   \n",
       "50%         0.798200  2.233947e+09      91.000000      65.000000   \n",
       "75%         0.855900  4.031443e+09      98.000000      84.000000   \n",
       "max         1.000000  1.563049e+10     126.000000     184.000000   \n",
       "\n",
       "                f26            f27            f28            f29  \\\n",
       "count  1.047730e+05  105471.000000  105471.000000  105471.000000   \n",
       "mean   1.108926e+06      92.134281      86.490683     103.850939   \n",
       "std    3.015962e+05      36.904526      30.830152      40.968777   \n",
       "min    1.230000e+02       0.000000       0.000000       0.000000   \n",
       "25%    9.267570e+05      84.000000      83.000000      91.000000   \n",
       "50%    1.115136e+06      94.780000      94.000000     108.000000   \n",
       "75%    1.293732e+06     104.000000     101.000000     128.750000   \n",
       "max    2.603664e+06     218.730000     160.490000     220.630000   \n",
       "\n",
       "                 f30            f31  ...           f750           f751  \\\n",
       "count  105471.000000  104773.000000  ...  104618.000000  104013.000000   \n",
       "mean       91.672933      90.045642  ...       8.115740       0.138719   \n",
       "std        32.681102      12.535453  ...      10.319706       0.115468   \n",
       "min         0.000000       1.000000  ...       0.000000       0.000000   \n",
       "25%        87.000000      84.000000  ...       1.700900       0.058420   \n",
       "50%        99.000000      92.000000  ...       4.261950       0.083637   \n",
       "75%       109.890000      99.000000  ...      10.210900       0.217172   \n",
       "max       159.900000     126.000000  ...      91.821900       0.500000   \n",
       "\n",
       "                f752           f753           f754           f755  \\\n",
       "count  105469.000000  105469.000000  105469.000000  105469.000000   \n",
       "mean        6.130018       5.500419       3.390325       2.158617   \n",
       "std         8.121672       7.143152       4.685670       3.163447   \n",
       "min         0.000000       0.000100       0.000000       0.000000   \n",
       "25%         1.202000       1.122200       0.595700       0.323300   \n",
       "50%         3.081600       2.840700       1.627000       0.957600   \n",
       "75%         7.569000       6.859100       4.152300       2.595800   \n",
       "max        77.673100      68.652100      48.579400      36.473500   \n",
       "\n",
       "                f756           f757           f758           f759  \\\n",
       "count  105238.000000  104671.000000  104671.000000  104671.000000   \n",
       "mean        0.119762      10.602136       8.782883       7.341984   \n",
       "std         0.063974      12.899936      10.998444       9.435965   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.076388       2.535400       1.957400       1.530850   \n",
       "50%         0.103507       5.855800       4.711500       3.830000   \n",
       "75%         0.156382      13.316650      10.987400       9.148000   \n",
       "max         0.497640     112.770300      95.343600      82.293100   \n",
       "\n",
       "                f760           f761           f762           f763      f764  \\\n",
       "count  104137.000000  105313.000000  105313.000000  103631.000000  105471.0   \n",
       "mean        0.136195      12.921228      12.103488      -0.253806       1.0   \n",
       "std         0.112682      14.973088      14.151640       0.237795       0.0   \n",
       "min         0.000000       0.000000       0.000000      -1.000000       1.0   \n",
       "25%         0.056469       3.361800       3.055100      -0.270300       1.0   \n",
       "50%         0.082008       7.564900       7.045500      -0.181800       1.0   \n",
       "75%         0.219453      16.463500      15.448100      -0.123900       1.0   \n",
       "max         0.500000     127.346800     120.425000       0.000000       1.0   \n",
       "\n",
       "                f765           f766           f767           f768  \\\n",
       "count  105470.000000  105471.000000  105471.000000  105471.000000   \n",
       "mean       -0.471021      -0.476605      -0.471572      -0.491973   \n",
       "std         0.284702       0.194983       0.263993       0.141869   \n",
       "min        -0.970000      -0.950000      -0.963000      -0.945000   \n",
       "25%        -0.710000      -0.630000      -0.699000      -0.575900   \n",
       "50%        -0.500000      -0.480000      -0.480000      -0.503100   \n",
       "75%        -0.230000      -0.330000      -0.248000      -0.420000   \n",
       "max         0.000000       0.000000       0.000000       0.000000   \n",
       "\n",
       "                f769           f770           f771           f772  \\\n",
       "count  105471.000000  105471.000000  105471.000000  105471.000000   \n",
       "mean       -8.786110      17.422543       5.800976      -4.246788   \n",
       "std         9.684043      18.548936       6.508555       4.828265   \n",
       "min       -85.450000       2.000000       0.000000     -43.160000   \n",
       "25%       -11.530000       5.000000       1.480000      -5.700000   \n",
       "50%        -5.440000      11.000000       3.570000      -2.600000   \n",
       "75%        -2.390000      23.000000       7.700000      -1.010000   \n",
       "max         0.000000     168.000000      58.120000       0.000000   \n",
       "\n",
       "                f773           f774           f775           f776  \\\n",
       "count  105471.000000  104407.000000  103946.000000  105471.000000   \n",
       "mean        3.273059       0.233852       0.014797       0.310246   \n",
       "std         3.766746       0.073578       1.039439       0.462597   \n",
       "min         0.000000       0.000000     -18.439600       0.000000   \n",
       "25%         0.740000       0.198400      -0.704275       0.000000   \n",
       "50%         1.990000       0.251800       0.375400       0.000000   \n",
       "75%         4.440000       0.283600       0.737100       1.000000   \n",
       "max        34.040000       0.473700      11.092000       1.000000   \n",
       "\n",
       "                f777           f778           loss  \n",
       "count  105471.000000  105471.000000  105471.000000  \n",
       "mean        0.322847     175.951589       0.799585  \n",
       "std         0.467567     298.294043       4.321120  \n",
       "min         0.000000       2.000000       0.000000  \n",
       "25%         0.000000      19.000000       0.000000  \n",
       "50%         0.000000      40.000000       0.000000  \n",
       "75%         1.000000     104.000000       0.000000  \n",
       "max         1.000000    1212.000000     100.000000  \n",
       "\n",
       "[8 rows x 752 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistics for each column\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "031a49103636eaa5dc31f4b6c2245aed1dfd19f1"
   },
   "outputs": [],
   "source": [
    "# # Missing Values\n",
    "\n",
    "# Function to calculate missing values by column\n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "6b9e205e77fa49de21972eb4884477ac0f8bc349",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 771 columns.\n",
      "There are 525 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f662</th>\n",
       "      <td>18833</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f663</th>\n",
       "      <td>18833</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f159</th>\n",
       "      <td>18736</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f160</th>\n",
       "      <td>18736</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f170</th>\n",
       "      <td>18417</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f169</th>\n",
       "      <td>18417</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f618</th>\n",
       "      <td>18407</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f619</th>\n",
       "      <td>18407</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f331</th>\n",
       "      <td>18067</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f330</th>\n",
       "      <td>18067</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f179</th>\n",
       "      <td>17162</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f180</th>\n",
       "      <td>17162</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f422</th>\n",
       "      <td>14235</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f653</th>\n",
       "      <td>13205</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f190</th>\n",
       "      <td>12234</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f189</th>\n",
       "      <td>12234</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f340</th>\n",
       "      <td>11911</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f341</th>\n",
       "      <td>11911</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f726</th>\n",
       "      <td>11282</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f665</th>\n",
       "      <td>11282</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f669</th>\n",
       "      <td>11282</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f668</th>\n",
       "      <td>11282</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f664</th>\n",
       "      <td>11282</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f667</th>\n",
       "      <td>11282</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f666</th>\n",
       "      <td>11282</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f640</th>\n",
       "      <td>9700</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f199</th>\n",
       "      <td>9068</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f200</th>\n",
       "      <td>9068</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f650</th>\n",
       "      <td>9003</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f651</th>\n",
       "      <td>9003</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f72</th>\n",
       "      <td>9002</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f586</th>\n",
       "      <td>8965</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f587</th>\n",
       "      <td>8965</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f649</th>\n",
       "      <td>8716</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f648</th>\n",
       "      <td>8657</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f588</th>\n",
       "      <td>8432</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f621</th>\n",
       "      <td>8180</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f620</th>\n",
       "      <td>8180</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f673</th>\n",
       "      <td>7343</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f672</th>\n",
       "      <td>7343</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f210</th>\n",
       "      <td>6861</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f209</th>\n",
       "      <td>6861</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f679</th>\n",
       "      <td>6393</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f149</th>\n",
       "      <td>2859</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f150</th>\n",
       "      <td>2859</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f32</th>\n",
       "      <td>2572</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f152</th>\n",
       "      <td>2561</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f151</th>\n",
       "      <td>2561</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f171</th>\n",
       "      <td>2561</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f181</th>\n",
       "      <td>2561</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Missing Values  % of Total Values\n",
       "f662           18833               17.9\n",
       "f663           18833               17.9\n",
       "f159           18736               17.8\n",
       "f160           18736               17.8\n",
       "f170           18417               17.5\n",
       "f169           18417               17.5\n",
       "f618           18407               17.5\n",
       "f619           18407               17.5\n",
       "f331           18067               17.1\n",
       "f330           18067               17.1\n",
       "f179           17162               16.3\n",
       "f180           17162               16.3\n",
       "f422           14235               13.5\n",
       "f653           13205               12.5\n",
       "f190           12234               11.6\n",
       "f189           12234               11.6\n",
       "f340           11911               11.3\n",
       "f341           11911               11.3\n",
       "f726           11282               10.7\n",
       "f665           11282               10.7\n",
       "f669           11282               10.7\n",
       "f668           11282               10.7\n",
       "f664           11282               10.7\n",
       "f667           11282               10.7\n",
       "f666           11282               10.7\n",
       "f640            9700                9.2\n",
       "f199            9068                8.6\n",
       "f200            9068                8.6\n",
       "f650            9003                8.5\n",
       "f651            9003                8.5\n",
       "f72             9002                8.5\n",
       "f586            8965                8.5\n",
       "f587            8965                8.5\n",
       "f649            8716                8.3\n",
       "f648            8657                8.2\n",
       "f588            8432                8.0\n",
       "f621            8180                7.8\n",
       "f620            8180                7.8\n",
       "f673            7343                7.0\n",
       "f672            7343                7.0\n",
       "f210            6861                6.5\n",
       "f209            6861                6.5\n",
       "f679            6393                6.1\n",
       "f149            2859                2.7\n",
       "f150            2859                2.7\n",
       "f32             2572                2.4\n",
       "f152            2561                2.4\n",
       "f151            2561                2.4\n",
       "f171            2561                2.4\n",
       "f181            2561                2.4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_table(data).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "c14e564d273adf7a71072ca75e1906e8e3d3b0a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\epam\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "ee7b2b30918685d90ad4b3062e205c7c81172ee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 771 columns.\n",
      "There are 12 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f206</th>\n",
       "      <td>1291</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f207</th>\n",
       "      <td>1291</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f390</th>\n",
       "      <td>698</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f391</th>\n",
       "      <td>698</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f626</th>\n",
       "      <td>698</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f627</th>\n",
       "      <td>698</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f695</th>\n",
       "      <td>698</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f698</th>\n",
       "      <td>698</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f138</th>\n",
       "      <td>182</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f137</th>\n",
       "      <td>177</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f276</th>\n",
       "      <td>101</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f277</th>\n",
       "      <td>101</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Missing Values  % of Total Values\n",
       "f206            1291                1.2\n",
       "f207            1291                1.2\n",
       "f390             698                0.7\n",
       "f391             698                0.7\n",
       "f626             698                0.7\n",
       "f627             698                0.7\n",
       "f695             698                0.7\n",
       "f698             698                0.7\n",
       "f138             182                0.2\n",
       "f137             177                0.2\n",
       "f276             101                0.1\n",
       "f277             101                0.1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_table(data).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "1a9d4567ec2eaa47b63110c90df17d6e38aeee87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 771 columns.\n",
      "There are 0 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Missing Values, % of Total Values]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "missing_values_table(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "2db9645d013be1732179ef0f682a2268c24df15d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103302, 771)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "d04cdc680bc805aeabaf6afcbc7d1f6c03e0e7d3"
   },
   "outputs": [],
   "source": [
    "# # # Exploratory Data Analysis\n",
    "\n",
    "for i in data.select_dtypes(include=['object']).columns:\n",
    "    data.drop(labels=i, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "90cc9e82a25bd463d7a6c477cfdc8e4680eaf1b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Distribution')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Single Variable Plots\n",
    "\n",
    "figsize=(8, 8)\n",
    "\n",
    "# Histogram of the loss\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.hist(data['loss'], bins = 100, edgecolor = 'k')\n",
    "plt.xlabel('Loss') \n",
    "plt.ylabel('Number of Clients');\n",
    "plt.title('Loss Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "1fe9f16cf8ed034ee3bb0e6fbd66f76f071746c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f612   -0.016943\n",
      "f776   -0.015111\n",
      "f315   -0.011106\n",
      "f70    -0.010740\n",
      "f314   -0.010689\n",
      "f323   -0.010676\n",
      "f69    -0.010269\n",
      "f322   -0.009299\n",
      "f734   -0.009284\n",
      "f738   -0.008635\n",
      "f1     -0.008162\n",
      "f631   -0.008097\n",
      "f428   -0.007973\n",
      "f666   -0.007868\n",
      "f299   -0.007778\n",
      "Name: loss, dtype: float64 \n",
      "\n",
      "f674    0.018999\n",
      "f536    0.026087\n",
      "f471    0.039538\n",
      "loss    1.000000\n",
      "f33          NaN\n",
      "f34          NaN\n",
      "f35          NaN\n",
      "f37          NaN\n",
      "f38          NaN\n",
      "f678         NaN\n",
      "f700         NaN\n",
      "f701         NaN\n",
      "f702         NaN\n",
      "f736         NaN\n",
      "f764         NaN\n",
      "Name: loss, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# # Correlations between Features and Target\n",
    "\n",
    "# Find all correlations and sort \n",
    "correlations_data = data.corr()['loss'].sort_values()\n",
    "\n",
    "# Print the most negative correlations\n",
    "print(correlations_data.head(15), '\\n')\n",
    "\n",
    "# Print the most positive correlations\n",
    "print(correlations_data.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "61a89b14640fbc08f925bb29e6fa17ec9cc757af"
   },
   "outputs": [],
   "source": [
    "for i in data.columns:\n",
    "    if len(set(data[i]))==1:\n",
    "        data.drop(labels=[i], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "8e04f8eadeeab0cdfffa98923e49f95b4f89064c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f612   -0.016943\n",
      "f776   -0.015111\n",
      "f315   -0.011106\n",
      "f70    -0.010740\n",
      "f314   -0.010689\n",
      "f323   -0.010676\n",
      "f69    -0.010269\n",
      "f322   -0.009299\n",
      "f734   -0.009284\n",
      "f738   -0.008635\n",
      "f1     -0.008162\n",
      "f631   -0.008097\n",
      "f428   -0.007973\n",
      "f666   -0.007868\n",
      "f299   -0.007778\n",
      "Name: loss, dtype: float64 \n",
      "\n",
      "f282    0.010726\n",
      "f251    0.010915\n",
      "f221    0.010968\n",
      "f556    0.011575\n",
      "f675    0.011606\n",
      "f13     0.011933\n",
      "f68     0.013375\n",
      "f599    0.014165\n",
      "f597    0.014165\n",
      "f670    0.014811\n",
      "f67     0.015012\n",
      "f674    0.018999\n",
      "f536    0.026087\n",
      "f471    0.039538\n",
      "loss    1.000000\n",
      "Name: loss, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find all correlations and sort \n",
    "correlations_data = data.corr()['loss'].sort_values()\n",
    "\n",
    "# Print the most negative correlations\n",
    "print(correlations_data.head(15), '\\n')\n",
    "\n",
    "# Print the most positive correlations\n",
    "print(correlations_data.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "668d758b12480015588a2dbf8a09268ac98adf08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103302, 741)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "19e87448a6d0ba70d09f1ceb9901b8b4cbdd07c8"
   },
   "outputs": [],
   "source": [
    "# # # Feature Engineering and Selection\n",
    "\n",
    "def remove_collinear_features(x, threshold):\n",
    "    '''\n",
    "    Objective:\n",
    "        Remove collinear features in a dataframe with a correlation coefficient\n",
    "        greater than the threshold. Removing collinear features can help a model\n",
    "        to generalize and improves the interpretability of the model.\n",
    "        \n",
    "    Inputs: \n",
    "        threshold: any features with correlations greater than this value are removed\n",
    "    \n",
    "    Output: \n",
    "        dataframe that contains only the non-highly-collinear features\n",
    "    '''\n",
    "    \n",
    "    # Dont want to remove correlations between loss\n",
    "    y = x['loss']\n",
    "    x = x.drop(columns = ['loss'])\n",
    "    \n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "            \n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                # Print the correlated features and the correlation value\n",
    "                # print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(columns = drops)\n",
    "    \n",
    "    # Add the score back in to the data\n",
    "    x['loss'] = y\n",
    "               \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "72a9179d42f2c3e287655146b97b7a11fcd005ed"
   },
   "outputs": [],
   "source": [
    "# Remove the collinear features above a specified correlation coefficient\n",
    "data = remove_collinear_features(data, 0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "0714bb6b8bfe04988becfd704daf41edf9b1043a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103302, 156)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "e7ff6c82948ad99aee1b8c5025d4508fca9426f6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82641, 155)\n",
      "(20661, 155)\n",
      "(82641, 1)\n",
      "(20661, 1)\n"
     ]
    }
   ],
   "source": [
    "# # # Split Into Training and Testing Sets\n",
    "\n",
    "# Separate out the features and targets\n",
    "features = data.drop(columns='loss')\n",
    "targets = pd.DataFrame(data['loss'])\n",
    "\n",
    "# Split into 80% training and 20% testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "5e4416f1bb6e26b561922dae8c81670d70cc974c"
   },
   "outputs": [],
   "source": [
    "# # Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "eeb1b6ca509da08d113656d439dcdaa6eb4b24bf"
   },
   "outputs": [],
   "source": [
    "# Convert y to one-dimensional array (vector)\n",
    "y_train = np.array(y_train).reshape((-1, ))\n",
    "y_test = np.array(y_test).reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "62df1f869bdcb157c0f242247ebaa2b61e3d227a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.06877109, -0.16688215,  1.03564494, ..., -0.61327879,\n",
       "         0.65159233, -0.66443318],\n",
       "       [-0.48425848,  2.15138579, -0.14682708, ..., -0.86473327,\n",
       "         0.74503266, -0.66443318],\n",
       "       [-0.43576466,  1.60591098, -0.73806309, ...,  1.07833542,\n",
       "         1.24726226,  1.50504223],\n",
       "       ...,\n",
       "       [ 0.84197055, -0.57598826,  1.03564494, ...,  0.82039823,\n",
       "        -0.75457294,  1.50504223],\n",
       "       [-1.69955094, -0.64417261,  0.44440893, ..., -1.37936099,\n",
       "        -0.4115703 , -0.66443318],\n",
       "       [-1.20154789,  1.06043617, -0.14682708, ..., -0.67299456,\n",
       "         0.87515049, -0.66443318]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "354fe7c290ae7d708590aeede77a2e1f4ba10aa5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47027681, -1.18964742,  1.03564494, ...,  0.83261565,\n",
       "         4.19883151,  1.50504223],\n",
       "       [ 0.34727464,  1.67409533, -0.73806309, ..., -1.49355648,\n",
       "         0.76570014, -0.66443318],\n",
       "       [ 1.02805453, -0.3714352 , -2.51177113, ..., -0.96808269,\n",
       "         1.03078733,  1.50504223],\n",
       "       ...,\n",
       "       [ 0.29720911,  0.92406747, -0.73806309, ..., -1.16904681,\n",
       "        -0.70741614, -0.66443318],\n",
       "       [ 0.85975052, -0.91691001,  1.03564494, ..., -0.85600654,\n",
       "        -0.90497014,  1.50504223],\n",
       "       [ 0.00752321, -1.18964742, -1.3292991 , ..., -1.04126255,\n",
       "         0.69224809, -0.66443318]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "59165d3c0c09f25fa49a8b70e13e057a75ebd662"
   },
   "outputs": [],
   "source": [
    "# # # Models to Evaluate\n",
    "\n",
    "# We will compare five different machine learning Cassification models:\n",
    "\n",
    "# 1 - Logistic Regression\n",
    "# 2 - K-Nearest Neighbors Classification\n",
    "# 3 - Suport Vector Machine\n",
    "# 4 - Naive Bayes\n",
    "# 5 - Random Forest Classification\n",
    "\n",
    "# Function to calculate mean absolute error\n",
    "def cross_val(X_train, y_train, model):\n",
    "    # Applying k-Fold Cross Validation\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    accuracies = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 5)\n",
    "    return accuracies.mean()\n",
    "\n",
    "# Takes in a model, trains the model, and evaluates the model on the test set\n",
    "def fit_and_evaluate(model):\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and evalute\n",
    "    model_pred = model.predict(X_test)\n",
    "    model_cross = cross_val(X_train, y_train, model)\n",
    "    \n",
    "    # Return the performance metric\n",
    "    return model_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "a5d839ce0829f4d6205b69767b7fa84b0d547744"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\epam\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Performance on the test set: Cross Validation Score = 0.0098\n"
     ]
    }
   ],
   "source": [
    "# # Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive = GaussianNB()\n",
    "naive_cross = fit_and_evaluate(naive)\n",
    "\n",
    "print('Naive Bayes Performance on the test set: Cross Validation Score = %0.4f' % naive_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "e90ced9e87d28f2532dd5f9856e41d59e52ed11b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\epam\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance on the test set: Cross Validation Score = 0.9067\n"
     ]
    }
   ],
   "source": [
    "# # Random Forest Classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\n",
    "random_cross = fit_and_evaluate(random)\n",
    "\n",
    "print('Random Forest Performance on the test set: Cross Validation Score = %0.4f' % random_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "687f4e0ee16b1605f62da51937433c6b1fb1da19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\epam\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:51:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\epam\\lib\\site-packages\\sklearn\\model_selection\\_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "C:\\ProgramData\\Anaconda3\\envs\\epam\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:53:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\epam\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:55:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\epam\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:57:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\epam\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:59:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\epam\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:01:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Gradiente Boosting Classification Performance on the test set: Cross Validation Score = 0.8948\n"
     ]
    }
   ],
   "source": [
    "# # Gradiente Boosting Classification\n",
    "from xgboost import XGBClassifier\n",
    "gb = XGBClassifier()\n",
    "gb_cross = fit_and_evaluate(gb)\n",
    "\n",
    "print('Gradiente Boosting Classification Performance on the test set: Cross Validation Score = %0.4f' % gb_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64b9e4bc8bd315eccbb57e2b4fdc69497bc6414b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "535f8320cd4758fd3c95c23eebca4d64da87f192"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da59ddb65c4111fcf40bad22703b180ad40816ee"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
